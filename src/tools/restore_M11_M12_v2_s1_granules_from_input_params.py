#!/usr/bin/env python
"""
Restore M11 and M12 values of the Sentinel-1 V2 data based on input parameters as generated by autoRIFT code base.
This script handles V2 Sentinel-1 granules that were originally corrected but lost their M11 and M12 values when
storing corrected granule to the file (encoding parameters were omitted).

Reference table, as provided by Joe, contains the following information per each row:
reference        S1A_IW_SLC__1SDV_20170203T162106_20170203T162132_015121_018B9A_1380
secondary        S1A_IW_SLC__1SDV_20170215T162105_20170215T162133_015296_019127_6E1E
v2_s3_bucket     its-live-data
v2_s3_key        velocity_image_pair/sentinel1/v02/N00E020/S1A_IW_SLC__1SDV_20170203T162106_20170203T162132_015121_018B9A_1380_X_S1A_IW_SLC__1SDV_20170215T162105_20170215T162133_015296_019127_6E1E_G0120V02_P099.nc
status           SUCCEEDED
to_correct       False
cor_s3_bucket    hyp3-its-live-contentbucket-s10lg85g5sp4
job_id           a851f0b5-9ae2-43fe-b81d-344eeae67b79

where the correction tifs for a particular file will all be in s3://[cor_s3_bucket]/[job_id]/

ATTN: This script should run from AWS EC2 instance to have fast access to the S3
bucket. It takes 2 seconds to upload the file to the S3 bucket from EC2 instance
vs. 1.5 minutes to upload the file from laptop to the S3 bucket.

Authors: Masha Liukis, Alex Gardner, Joe Kennedy
"""
import argparse
import boto3
from datetime import datetime
from botocore.exceptions import ClientError
import dask
from dask.diagnostics import ProgressBar
import json
import logging
import numpy as np
import os
import pandas as pd
import s3fs
import xarray as xr

from itscube_types import DataVars, Coords, Output
from mission_info import Encoding


class RestoreM11M12Values:
    """
    Restore corrected M11 and M12 values for existing V2 Sentinel1 granules, copy corrected granule and corresponding PNG files
    to the target location in AWS S3 bucket.
    """
    NC_ENGINE = 'h5netcdf'

    # Reference file that stores M11/M12 values to restore: have to divide by date_dt when restoring
    CONVERSION_MATRICES_NC_FILE = 'conversion_matrices.nc'

    # S3 bucket with granules
    BUCKET = 'its-live-data'

    # Source S3 bucket directory
    SOURCE_DIR = 'velocity_image_pair/sentinel1/v02'

    GRANULE_LIST_FILE = 'used_granules.json'

    # Target S3 bucket directory
    TARGET_DIR = None

    # Local directory to store corrected granules before copying them to the S3 bucket
    LOCAL_DIR = 'sandbox-correct-S1'

    # Number of granules to process in parallel
    CHUNK_SIZE = 100

    # Number of Dask workers for parallel processing
    DASK_WORKERS = 8

    DRYRUN = False

    def __init__(self, granule_table: str):
        """
        Initialize object.

        Inputs:
        =======
        granule_table: File that stores information for granule correction.
        """
        self.s3 = s3fs.S3FileSystem()

        # Use another s3fs object to read reference TIF data
        self.s3_ref = s3fs.S3FileSystem()

        self.table = pd.read_parquet(granule_table)

        logging.info(f"Total number of granules to correct: {len(self.table)}")

        # Store listings of original and target granules to the files in case we want to store/load granules lists
        # for subsequent runs
        existing_granules_file = os.path.join(
            RestoreM11M12Values.BUCKET,
            RestoreM11M12Values.SOURCE_DIR,
            RestoreM11M12Values.GRANULE_LIST_FILE
        )

        self.all_original_granules = []

        # Read a list of original granules from the target S3 bucket
        with self.s3.open(existing_granules_file, 'r') as ins3file:
            self.all_original_granules = json.load(ins3file)
            logging.info(f"Loaded {len(self.all_original_granules)} original granules from '{existing_granules_file}'")

        # Create a map of all basenames to the location in s3 bucket
        self.all_original_granules_map = {os.path.basename(each): each for each in self.all_original_granules}
        logging.info(f'Created map of granule name to the s3 location: {len(self.all_original_granules_map)} entries')

    def __call__(self, start_index: int = 0, stop_index: int = 0):
        """
        Restore M11 and M12 from provided input parameters files and copy restored granule along with corresponding PNG files
        to the target location in S3 bucket.
        """
        num_to_fix = len(self.table)

        if stop_index > 0:
            num_to_fix = stop_index

        num_to_fix -= start_index

        # For debugging only
        # num_to_fix = 3

        start = start_index
        logging.info(f"{num_to_fix} granules to correct...")

        if num_to_fix <= 0:
            logging.info("Nothing to fix, exiting.")
            return

        if not os.path.exists(RestoreM11M12Values.LOCAL_DIR):
            os.mkdir(RestoreM11M12Values.LOCAL_DIR)

        while num_to_fix > 0:
            num_tasks = RestoreM11M12Values.CHUNK_SIZE if num_to_fix > RestoreM11M12Values.CHUNK_SIZE else num_to_fix

            logging.info(f"Starting tasks {start}:{start+num_tasks}")

            tasks = [
                dask.delayed(RestoreM11M12Values.correct)(
                    each['v2_granule'],     # granule to fix
                    each['cor_s3_bucket'],  # reference bucket with M11/M12
                    each['job_id'],         # sub-directory in reference bucket with M11/M12
                    self.s3,
                    self.s3_ref,
                    self.all_original_granules_map[each['v2_granule']]  # full path of original granule in the s3 bucket
                ) for _, each in self.table.iloc[start:start+num_tasks].iterrows()
            ]
            results = None

            with ProgressBar():
                # Display progress bar
                results = dask.compute(
                    tasks,
                    scheduler="processes",
                    num_workers=RestoreM11M12Values.DASK_WORKERS
                )

            for each_result in results[0]:
                logging.info("-->".join(each_result))

            num_to_fix -= num_tasks
            start += num_tasks

    @staticmethod
    def correct(
        granule_basename: str,
        ref_bucket: str,
        ref_dir: str,
        s3: s3fs.S3FileSystem,
        s3_ref: s3fs.S3FileSystem,
        granule_s3_path: str
    ):
        """
        Correct S1 data for the granule residing in S3 bucket. Copy corrected granule along with corresponding PNG files
        to the new S3 location.

        Inputs:
        =======
        granule_basename: Granule path within S3 bucket.
        ref_bucket: S3 bucket with reference data for correction.
        ref_dir: S3 directory path that holds reference data for correction.
        s3: s3fs.S3FileSystem object to access original ITS_LIVE granules for correction.
        s3_ref: s3fs.S3FileSystem object to access data for correction.
        granule_s3_path: full path of original granule in the s3 bucket.
        """
        msgs = [f'Processing {granule_s3_path}']

        # Read granule to correct
        ds = None

        # Read the granule for correction in
        with s3.open(granule_s3_path, mode='rb') as fhandle:
            with xr.open_dataset(fhandle, engine=RestoreM11M12Values.NC_ENGINE) as ds:
                ds = ds.load()

        # Get the date separation in days from the granule to multiply M11 and M12 by
        date_dt = ds.img_pair_info.attrs['date_dt']

        # Get mask for invalid "v" values, have to apply the same to restored M11 and M12
        invalid_v_mask = np.isnan(ds.v)

        # Read M11 and M12 from reference file
        s3_m11_m12_file = os.path.join(ref_bucket, ref_dir, RestoreM11M12Values.CONVERSION_MATRICES_NC_FILE)

        msgs.append(f'Reading: {s3_m11_m12_file}')
        with s3.open(s3_m11_m12_file, mode='rb') as fhandle:
            with xr.open_dataset(fhandle, engine=RestoreM11M12Values.NC_ENGINE) as m11_m12_ds:
                m11_m12_ds = m11_m12_ds.load()

                # Crop dataset to granule's X/Y ranges
                mask_x = (m11_m12_ds.x >= ds.x.min().item()) & (m11_m12_ds.x <= ds.x.max().item())
                mask_y = (m11_m12_ds.y >= ds.y.min().item()) & (m11_m12_ds.y <= ds.y.max().item())
                mask = (mask_x & mask_y)

                cropped_m11_m12 = m11_m12_ds.where(mask, drop=True)

                # Apply valid v mask of the granule to M11 and M12 values (to have the same coverage)
                nan_cropped_m11 = cropped_m11_m12.M11.where(~invalid_v_mask, other=np.nan)

                # Restore M11 and M12 values based on input parameter file values * date_dt
                ds[DataVars.M11] = nan_cropped_m11 * date_dt

                nan_cropped_m12 = cropped_m11_m12.M12.where(~invalid_v_mask, other=np.nan)
                ds[DataVars.M12] = nan_cropped_m12 * date_dt

                for each_var in [DataVars.M11, DataVars.M12]:
                    if Output.SCALE_FACTOR in ds[each_var].encoding:
                        # Remove both compression encoding attributes if present as will need to calculate new ones
                        del ds[each_var].encoding[Output.SCALE_FACTOR]
                        del ds[each_var].encoding[Output.ADD_OFFSET]

        # Add date when granule was updated
        ds.attrs['date_updated'] = datetime.now().strftime('%d-%b-%Y %H:%M:%S')

        # Save updated granule to the local file

        # Set chunking for 2D data variables
        dims = ds.dims
        num_x = dims[Coords.X]
        num_y = dims[Coords.Y]

        # Compute chunking like AutoRIFT does:
        # https://github.com/ASFHyP3/hyp3-autorift/blob/develop/hyp3_autorift/vend/netcdf_output.py#L410-L411
        chunk_lines = np.min([np.ceil(8192/num_y)*128, num_y])
        two_dim_chunks_settings = (chunk_lines, num_x)

        granule_encoding = Encoding.SENTINEL1.copy()

        for each_var, each_var_settings in granule_encoding.items():
            if each_var_settings[Output.FILL_VALUE_ATTR] is not None:
                each_var_settings[Output.CHUNKSIZES_ATTR] = two_dim_chunks_settings

        # Set compression encoding attributes for M11 and M12: have to recompute since we multiply original values by date_dt
        # Do like hyp3 does: https://github.com/ASFHyP3/hyp3-autorift/blob/develop/src/hyp3_autorift/s1_isce2.py#L186
        y1 = -50
        y2 = 50

        for each_var in [DataVars.M11, DataVars.M12]:
            # Recompute compression encoding attributes for restored M11/M12 values
            x1 = np.nanmin(ds[each_var])
            x2 = np.nanmax(ds[each_var])

            C = [(y2 - y1) / (x2 - x1), y1 - x1 * (y2 - y1) / (x2 - x1)]

            granule_encoding[each_var][Output.SCALE_FACTOR] = np.float32(1 / C[0])
            granule_encoding[each_var][Output.ADD_OFFSET] = np.float32(-C[1] / C[0])

            no_data_mask = np.isnan(ds[each_var])
            ds[each_var].data[no_data_mask] = DataVars.MISSING_VALUE * np.float32(1 / C[0]) + np.float32(-C[1] / C[0])

        fixed_file = os.path.join(RestoreM11M12Values.LOCAL_DIR, granule_basename)

        # Save to local file
        ds.to_netcdf(fixed_file, engine='h5netcdf', encoding=granule_encoding)

        # Upload corrected granule to the bucket - format sub-directory based on new cropped values
        if not RestoreM11M12Values.DRYRUN:
            s3_client = boto3.client('s3')
            try:
                # Upload granule to the target directory in the bucket:
                # remove bucket name from the target path, replace with target directory for corrected granule
                target = granule_s3_path.replace(
                    RestoreM11M12Values.BUCKET + '/' + RestoreM11M12Values.SOURCE_DIR,
                    RestoreM11M12Values.TARGET_DIR
                )

                # msgs.append(f"Uploading to {target}")
                msgs.append(f"Uploading {fixed_file} to {RestoreM11M12Values.BUCKET}: {target}")
                s3_client.upload_file(fixed_file, RestoreM11M12Values.BUCKET, target)

                # msgs.append(f"Removing local {fixed_file}")
                os.unlink(fixed_file)

                # There are corresponding browse and thumbprint images to transfer
                bucket = boto3.resource('s3').Bucket(RestoreM11M12Values.BUCKET)

                for target_ext in ['.png', '_thumb.png']:
                    target_key = target.replace('.nc', target_ext)

                    # Path to original PNG file in the S3 bucket - just copy to new location in s3
                    source_key = target_key.replace(RestoreM11M12Values.TARGET_DIR, RestoreM11M12Values.SOURCE_DIR).replace('.nc', target_ext)

                    msgs.append(f"Uploading {source_key} to {RestoreM11M12Values.BUCKET}: {target_key}")
                    source_dict = {
                        'Bucket': RestoreM11M12Values.BUCKET,
                        'Key': source_key
                    }

                    bucket.copy(source_dict, target_key)
                    msgs.append(f'Copying {target_ext} to s3')

            except ClientError as exc:
                msgs.append(f"ERROR: {exc}")

        return msgs


def main():
    parser = argparse.ArgumentParser(
        description=__doc__.split('\n')[1],
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )
    parser.add_argument(
        '--read_granule_list',
        action='store_true',
        help=f'Read granule file list from {RestoreM11M12Values.GRANULE_LIST_FILE} stored in the target S3 bucket only (to avoid time consuming glob). '
    )
    parser.add_argument(
        '-c', '--chunk_size',
        type=int,
        default=100,
        help='Number of granules to process in parallel [%(default)d]'
    )
    parser.add_argument(
        '-t', '--target_bucket_dir',
        type=str,
        default='velocity_image_pair/sentinel1-restoredM/v02',
        help='AWS S3 bucket and directory to store corrected granules'
    )
    parser.add_argument(
        '-l', '--local_dir',
        type=str,
        default='sandbox-sentinel1',
        help='Directory to store fixed granules before uploading them to the S3 bucket'
    )
    parser.add_argument(
        '-w', '--dask_workers',
        type=int,
        default=8,
        help='Number of Dask parallel workers [%(default)d]'
    )
    parser.add_argument(
        '-s', '--start_granule',
        type=int,
        default=0,
        help='Index for the start granule to process (if previous processing terminated) [%(default)d]'
    )
    parser.add_argument(
        '-e', '--stop_granule',
        type=int,
        default=0,
        help='Index for the last granule to process (if splitting processing across multiple EC2s) [%(default)d]'
    )
    parser.add_argument(
        '--granule_table',
        default='sentinel1_restore_m11m12_files_unique.parquet',
        help='Table that provides the reference data for the granules to correct [%(default)s]'
    )
    parser.add_argument(
        '--dryrun',
        action='store_true',
        help='Dry run, do not actually copy any data to AWS S3 bucket'
    )

    args = parser.parse_args()
    logging.basicConfig(format='%(asctime)s - %(levelname)s - %(message)s',
                        datefmt='%m/%d/%Y %I:%M:%S %p', level=logging.INFO)

    logging.info(f"Args: {args}")

    RestoreM11M12Values.CHUNK_SIZE = args.chunk_size
    RestoreM11M12Values.DASK_WORKERS = args.dask_workers
    RestoreM11M12Values.TARGET_DIR = args.target_bucket_dir
    RestoreM11M12Values.LOCAL_DIR = args.local_dir
    RestoreM11M12Values.DRYRUN = args.dryrun

    process_granules = RestoreM11M12Values(args.granule_table)
    process_granules(args.start_granule, args.stop_granule)


if __name__ == '__main__':
    main()

    logging.info("Done.")
